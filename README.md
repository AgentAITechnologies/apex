# Welcome to *apex*™!

## Project Overview
*apex*™ is a system that enables LLM powered agents to act as the primary interface between the user and system, enabling advanced AI collaboration for any task. It also connects to a hosted memory of prior experiences, which allows *apex*™ to learn from previous experiences.

## Installation Instructions
How to install and run the project.

## Tips
We encourage you to push *apex*™ to the limits of its capability, and even a little beyond what you think it can handle.

*apex*™ learns from prior experience and human feedback. By allowing *apex*™ to develop a diverse experience pool with salient feedback, its performance will increase over time. We encourage you to allow full telemetry so *apex*™ may learn from your interactions *(you will have the opportunity to review any and all information sent to us)*.

That being said, this product is in an *experimental* stage of development. Do not expect it to be able to reliably complete tasks involving high levels of complexity or scale at this time (we do expect it to be capable of such tasks with further feature implementations and a broad experience pool).

*apex*™ is best suited for tasks that directly map onto programmatic interaction with the computer (such as Python or shell scripts) than tasks that require mouse and keyboard emulation or visual screen interpretation. This tool is currently better equipped to, say, compile a list of machines on a network vulnerable to some new exploit and automatically patch them than to research especially fluffy cat breeds online.

*apex*™ may not always complete a task the way you want it the first time. In fact, at this time, it will probably fail more than it succeeds. This is expected at this stage, as the experience pool is incredibly small, and many important features are not yet implemented. By enabling telemetry and providing high-quality feedback, expect performance on tasks related to the ones you have tried to increase over time (it takes a little while for new experiences to be ingested by our memory backend). __This architecture is built for the future. It is not constrained by fixed tools, and leverages LLM-powered soft reasoning wherever possible. As the experience pool grows, the codebase matures, and LLMs become more powerful, this tool will become increasingly generally capable.__

## Usage Examples


## Contribution Guidelines

We welcome contributions from the community to help improve our project! Whether you're fixing bugs, adding new features, improving documentation, or contributing in any other way, your efforts are highly appreciated. Here’s how you can get involved:

1. **Reporting Bugs:**  
   If you encounter a bug, please report it through our Discord server in the `#bug-reports` channel using our provided bug report template. 

2. **Suggesting Enhancements:**  
   We’re always looking to improve our project. If you have ideas for new features or enhancements, please follow our feautre request template and subit it to the `#feature-requests` channel on our Discord server.

3. **Submitting Pull Requests:**  
   If you are looking to submit a pull request, please fill out our provided pull request template and submit your PR through GitHub. 

4. **Reviewing and Merging:**  
   Once you submit a pull request, it will be reviewed. We may ask for additional changes before it can be merged. Please be responsive to feedback and update your PR as requested.

5. **Contributor License Agreement (CLA):**  
   By contributing to this project, you agree to sign our Contributor License Agreement (CLA). This ensures that we have the rights to distribute your contributions under our chosen licenses. You can find more information and sign the CLA [insert link or process here].

Thank you for contributing to our project!
